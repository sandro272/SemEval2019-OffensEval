#! /usr/bin/env python

import numpy as np
import pandas as pd
from collections import Counter
import re
import io

# pd.set_option("display.line_width",1000)
# pd.set_option("display.max_columns",1000)
# pd.set_option("display.max_rows",1000)
# pd.set_option("display.max_colwidth",1000)

# train = pd.read_csv("../train_data/train_subtask_a", header = 0, sep = "\t", quoting = 3,encoding = "utf-8")
# print(train["tweet"])


'''
sentences = ["@USER @USER Go home youâ€™re drunk!!! @USER #MAGA #Trump2020 ğŸ‘ŠğŸ‡ºğŸ‡¸ğŸ‘Š URL",
             "@USER Right on ğŸ‘ğŸ‘  #MAGA ğŸ‡ºğŸ‡¸ğŸ™ğŸ‡ºğŸ‡¸ #WWG1WGA ğŸ‡ºğŸ‡¸ğŸ‘ŠğŸ‡ºğŸ‡¸",
             "It is a pleasure see old faces coming back to training and many of you utilising the new timetable ğŸ‘ŠğŸ»ğŸ‘ŠğŸ» ",
             "Corrupt period...ğŸ˜†ğŸ˜†ğŸ˜†ğŸ‘ŠğŸ½ğŸ‘ŠğŸ½last week u liberals were saying he wonâ€™t release bc he has something to hide ğŸ˜†ğŸ˜†ğŸ˜†ğŸ˜†ğŸ˜† o boy u pple those pple  that",
             "@USER @USER @USER #SimonSays Jack Viney eats bricks for breakfast ğŸ‘Š  Favourite moment of the game was Melkshams colossal celebration. He is one of our heart and soul players. URL"
            ]


for sentence in sentences:
    print(type(sentence))                            #  <class 'str'>
    if len(sentence) > 0:
        us = re.findall("@USER", sentence)
        res = Counter(us)
        print(res)

'''

'''

def read_file():

    # f = open("../train_data/some_train.txt")
    # readline = f.readlines()

    train = pd.read_csv("../train_data/train_subtask_a", header = 0, sep = "\t", quoting = 3,)
    dic_word = []                        #å­˜å‚¨å•è¯

    # å¾—åˆ°æ–‡ç« æˆ–è€…æ–‡æœ¬çš„å•è¯å¹¶å­˜å…¥åˆ—è¡¨ä¸­

    for tweet in train["tweet"]:
        #å› ä¸ºåŸæ–‡ä¸­æ¯ä¸ªå•è¯éƒ½æ˜¯ç”¨ç©ºæ ¼æˆ–è€…é€—å·åŠ ç©ºæ ¼åˆ†å¼€çš„

        # tweet = tweet.replace(",", " ")    #å»é™¤é€—å·ï¼Œç”¨ç©ºæ ¼æ¥åˆ†å¼€å•è¯
        # tweet = tweet.strip()               #é™¤å»å·¦å³çš„ç©ºæ ¼


        tweet = re.sub("@[\w]*", " ", tweet)

        tweet = re.sub("[a-zA-Z0-9]"," ",tweet)

        tweet = re.sub("[\"\'!?,.]", "", tweet).strip()

        word = tweet.split()

        dic_word.extend(word)

    print(dic_word)
    return dic_word

def clear_count(lists):
    #å»é™¤é‡å¤çš„å€¼
    single_word = {}
    single_word = single_word.fromkeys(lists)  #æ­¤æ®µä»£ç çš„æ„æ€æ˜¯å°†listsçš„å…ƒç´ ä½œä¸ºsingle_wordçš„é”®å€¼key    #é€šè¿‡è¿™ä¸ªä»£ç å¯ä»¥é™¤å»é‡å¤çš„åˆ—è¡¨å…ƒç´ 
    word1 = list(single_word.keys())
    #ç»Ÿè®¡å•è¯å‡ºç°çš„æ¬¡æ•°ï¼Œå¹¶å­˜å…¥ä¸€ä¸ªå­—å…¸ä¸­
    for i in word1:
        single_word[i] = lists.count(i)

    return single_word


# clear_count(read_file())


def sort_1(single_word):

    # del[single_word[""]]               #åˆ é™¤' 'å­—ç¬¦ï¼Œå‘ç°å­—å…¸ä¸­å­˜åœ¨ç©ºå…ƒç´ ï¼Œæ‰€ä»¥åˆ é™¤
                                      #æ’åºï¼ŒæŒ‰ç…§valuesè¿›è¡Œæ’åºï¼Œå¦‚æœæ˜¯æŒ‰ç…§keyè¿›è¡Œæ’åºç”¨çš„d[0]
    single_word_1 = {}
    single_word_1 = sorted(single_word.items(), key = lambda d:d[1], reverse = True)
                                      #å¾—åˆ°çš„æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œé‡Œé¢çš„å…ƒç´ æ˜¯å…ƒç¥–ï¼Œæ‰€ä»¥å†æŠŠå®ƒè½¬åŒ–ä¸ºå­—å…¸ï¼Œä¸è½¬ä¹Ÿå¯ä»¥
    single_word_1 = dict(single_word_1)

    return single_word_1


def main(single_word_1):
    i = 0
    for x,y in single_word_1.items():
        if i < 100:                #è¾“å‡ºå‰20
            print("The word is:","{}".format(x),  ",its amount is:","{}".format(y))
            i += 1
            continue
        else:
            break
    return i


main(sort_1(clear_count(read_file())))

'''

class Counter:
    def __init__(self, path):
        """
        :param path: æ–‡ä»¶è·¯å¾„
        """
        self.mapping = dict()
        with io.open(path, encoding="utf-8") as f:
            data = f.read()
            # words = [s.lower() for s in re.findall("\w+\'", data)]
            words = [s for s in re.findall("\w+\'+", data)]
            for word in words:
                self.mapping[word] = self.mapping.get(word, 0) + 1

    def most_common(self, n):
        assert n > 0, "n should be large than 0"
        return sorted(self.mapping.items(), key=lambda item: item[1], reverse=True)[:n]

if __name__ == '__main__':
    # train = pd.read_csv("../train_data/train_subtask_a", header=0, sep="\t", quoting=3, )
    most_common_5 = Counter("../train_data/train_subtask_a.tsv").most_common(1000)
    for item in most_common_5:
        print(item)